{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae6a03c-c35a-4e74-a694-9ddb2de46b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] yolo-seg-11042025/road-tr-od-ss-95-5 → Train: 7235, Valid: 190, Test: 191\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "README: Segmentation Dataset Split, Symlink, and Training Utilities\n",
    "\n",
    "This script provides utility functions for:\n",
    "- Splitting a dataset into train/validation/test splits (with symlinks for images/masks),\n",
    "- Loading segmentation datasets with PyTorch,\n",
    "- Training a segmentation model and saving the loss history and checkpoints,\n",
    "- Plotting training loss.\n",
    "\n",
    "All code is fully modular, robust to data issues, and includes informative error handling.\n",
    "\n",
    "Requirements:\n",
    "- torch\n",
    "- torchvision\n",
    "- albumentations\n",
    "- opencv-python\n",
    "- numpy\n",
    "- matplotlib\n",
    "- tqdm\n",
    "\n",
    "Author: Bahadir Akin Akgul\n",
    "Date: 13.07.2025\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "\n",
    "# 🔧 Dataset symlink creation with train/valid/test split\n",
    "def create_split_with_test_symlink_dataset(original_dataset_dir, new_dataset_dir, ratio=(0.7, 0.3), seed=42):\n",
    "    assert sum(ratio) == 1.0, \"Total split ratio must be 1.0\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    all_jpgs = list(Path(original_dataset_dir, \"train\").glob(\"*.jpg\")) + \\\n",
    "               list(Path(original_dataset_dir, \"valid\").glob(\"*.jpg\"))\n",
    "    random.shuffle(all_jpgs)\n",
    "\n",
    "    total = len(all_jpgs)\n",
    "    train_count = int(total * ratio[0])\n",
    "    rest_count = total - train_count\n",
    "    valid_count = rest_count // 2\n",
    "    test_count = rest_count - valid_count\n",
    "\n",
    "    train_imgs = all_jpgs[:train_count]\n",
    "    valid_imgs = all_jpgs[train_count:train_count + valid_count]\n",
    "    test_imgs = all_jpgs[train_count + valid_count:]\n",
    "\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        split_dir = Path(new_dataset_dir) / split\n",
    "        split_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for f in split_dir.glob(\"*\"):\n",
    "            f.unlink()\n",
    "\n",
    "    def create_symlinks(img_list, split_name):\n",
    "        for img_path in img_list:\n",
    "            mask_path = img_path.with_name(img_path.stem + \"_mask.png\")\n",
    "            try:\n",
    "                os.symlink(img_path.resolve(), Path(new_dataset_dir) / split_name / img_path.name)\n",
    "                os.symlink(mask_path.resolve(), Path(new_dataset_dir) / split_name / mask_path.name)\n",
    "            except Exception as e:\n",
    "                print(f\"[SYMLINK ERROR] {e}\")\n",
    "\n",
    "    create_symlinks(train_imgs, \"train\")\n",
    "    create_symlinks(valid_imgs, \"valid\")\n",
    "    create_symlinks(test_imgs, \"test\")\n",
    "\n",
    "    print(f\"[✓] {new_dataset_dir} → Train: {train_count}, Valid: {valid_count}, Test: {test_count}\")\n",
    "\n",
    "# 📦 Robust Segmentation Dataset class\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "    def __len__(self): return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_name = self.images[idx]\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            mask_path = img_path.replace(\".jpg\", \"_mask.png\")\n",
    "\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise FileNotFoundError(f\"[IMG ERROR] Could not read file: {img_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None or image.shape[:2] != mask.shape:\n",
    "                print(f\"[WARN] Mask error: {mask_path}\")\n",
    "                mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "\n",
    "            if self.transform:\n",
    "                transformed = self.transform(image=image, mask=mask)\n",
    "                return transformed[\"image\"], transformed[\"mask\"].long()\n",
    "\n",
    "            return image, torch.tensor(mask).long()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[DATA ERROR] {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))  # move to the next item\n",
    "\n",
    "# 🎯 Training function with loss recording and checkpointing\n",
    "def train_model(model, train_loader, optimizer, criterion, start_epoch=0, epochs=100, checkpoint_path=\"checkpoint.pth\", loss_log_path=\"train_losses.json\"):\n",
    "    os.makedirs(os.path.dirname(loss_log_path), exist_ok=True)\n",
    "    all_losses = []\n",
    "    if os.path.exists(loss_log_path):\n",
    "        with open(loss_log_path, \"r\") as f:\n",
    "            all_losses = json.load(f)\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            if images.size(0) < 2:\n",
    "                continue\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)[\"out\"]\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        all_losses.append(avg_loss)\n",
    "        print(f\"[{epoch+1}/{epochs}] Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        with open(loss_log_path, \"w\") as f:\n",
    "            json.dump(all_losses, f)\n",
    "\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "# 📈 Loss plotting function\n",
    "def plot_losses(loss_log_path=\"train_losses.json\"):\n",
    "    if os.path.exists(loss_log_path):\n",
    "        with open(loss_log_path, \"r\") as f:\n",
    "            losses = json.load(f)\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(range(1, len(losses)+1), losses, marker='o')\n",
    "        plt.title(\"Training Loss per Epoch\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Loss file not found!\")\n",
    "\n",
    "# 🚀 Main\n",
    "if __name__ == \"__main__\":\n",
    "    # 📁 Create new split dataset with symlinks\n",
    "    base_dataset = \"YOUR_ORIGINAL_DATASET_DIR/road-tr-od-ss\"\n",
    "    new_dataset = \"YOUR_NEW_DATASET_DIR/road-tr-od-ss-95-5\"\n",
    "    create_split_with_test_symlink_dataset(base_dataset, new_dataset, ratio=(0.95, 0.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c7676-17b8-4ac6-9d19-ebc435de2cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
