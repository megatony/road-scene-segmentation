{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ed93fa-aa47-4d67-a9e3-d36ff77c01a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arf/home/baakgul/.local/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Evaluating model in: road-tr-od-ss-65-35-results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: deeplabv3_metrics_35-.csv\n",
      "\n",
      "Evaluating model in: road-tr-od-ss-70-30-results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:34<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: deeplabv3_metrics_30-.csv\n",
      "\n",
      "Evaluating model in: road-tr-od-ss-75-25-results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:29<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: deeplabv3_metrics_25-.csv\n",
      "\n",
      "Evaluating model in: road-tr-od-ss-95-5-results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: deeplabv3_metrics_5-.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "README: Semantic Segmentation Model Citywise Metrics Evaluator\n",
    "\n",
    "This script evaluates multiple trained DeepLabV3-MobileNetV3 models on corresponding test datasets,\n",
    "and computes classwise segmentation metrics (precision, recall, F1-score, IoU) for each city represented in the data.\n",
    "\n",
    "Features:\n",
    "- Loads trained segmentation models and their test sets.\n",
    "- Splits evaluation by city keywords parsed from image file names.\n",
    "- Computes per-class and per-city precision, recall, F1-score, and IoU using torchmetrics.\n",
    "- Outputs results as CSV files (one per model/test set).\n",
    "\n",
    "How to use:\n",
    "- Place your trained models and corresponding test image folders.\n",
    "- Configure model/test set pairs in `model_dataset_pairs`.\n",
    "- Update city keywords in `city_keywords` and their English translations if needed.\n",
    "- Run the script to get per-city, per-class metrics as CSV.\n",
    "\n",
    "Requirements:\n",
    "- torch\n",
    "- torchvision\n",
    "- albumentations\n",
    "- opencv-python\n",
    "- numpy\n",
    "- pandas\n",
    "- tqdm\n",
    "- torchmetrics\n",
    "\n",
    "Author: Bahadir Akin Akgul\n",
    "Date: 13.07.2025\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import precision, recall, f1_score, jaccard_index\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# City keywords and their corresponding English names\n",
    "city_keywords = {\n",
    "    'istanbul': ['libadiye', 'levent', 'taksim', 'ciragan', 'barbaros', 'dolmabahce', 'bagdat', 'muallim', 'katar'],\n",
    "    'paris': ['paris-champs'],\n",
    "    'munich': ['munih'],\n",
    "    'marseille': ['marsilya']\n",
    "}\n",
    "\n",
    "city_translation = {\n",
    "    'istanbul': 'Istanbul',\n",
    "    'paris': 'Paris',\n",
    "    'munich': 'Munich',\n",
    "    'marseille': 'Marseille'\n",
    "}\n",
    "\n",
    "class_names = ['Background', 'Person', 'Road', 'Vehicle']\n",
    "\n",
    "# Custom Dataset class for segmentation\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        mask_path = img_path.replace(\".jpg\", \"_mask.png\")\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if mask is None or image.shape[:2] != mask.shape:\n",
    "            mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        else:\n",
    "            mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        mask = mask.astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"].long()\n",
    "\n",
    "        return image, mask, img_name\n",
    "\n",
    "# Albumentations transformations\n",
    "transform = A.Compose([\n",
    "    A.Resize(1024, 768),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "\n",
    "# Evaluation function for per-city, per-class metrics\n",
    "def evaluate_and_collect(model_dir, dataset_dir):\n",
    "    print(f\"\\nEvaluating model in: {model_dir}\")\n",
    "    model_path = os.path.join(model_dir, \"trained_model.pth\")\n",
    "\n",
    "    NUM_CLASSES = 4\n",
    "    model = torchvision.models.segmentation.deeplabv3_mobilenet_v3_large(weights=None)\n",
    "    model.classifier[4] = torch.nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    test_dataset = SegmentationDataset(dataset_dir, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=40, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    city_class_metrics = {\n",
    "        city: {cls: {'precision': 0, 'recall': 0, 'f1': 0, 'iou': 0, 'count': 0}\n",
    "               for cls in range(NUM_CLASSES)} for city in city_keywords\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks, names in tqdm(test_loader):\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            outputs = model(images)[\"out\"]\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            for i, name in enumerate(names):\n",
    "                lower_name = name.lower()\n",
    "                city = None\n",
    "                for key, keywords in city_keywords.items():\n",
    "                    if any(keyword in lower_name for keyword in keywords):\n",
    "                        city = key\n",
    "                        break\n",
    "\n",
    "                if city:\n",
    "                    pred_single = preds[i].unsqueeze(0)\n",
    "                    mask_single = masks[i].unsqueeze(0)\n",
    "\n",
    "                    precision_per_class = precision(pred_single, mask_single, task=\"multiclass\", num_classes=NUM_CLASSES, average=None)\n",
    "                    recall_per_class = recall(pred_single, mask_single, task=\"multiclass\", num_classes=NUM_CLASSES, average=None)\n",
    "                    f1_per_class = f1_score(pred_single, mask_single, task=\"multiclass\", num_classes=NUM_CLASSES, average=None)\n",
    "                    iou_per_class = jaccard_index(pred_single, mask_single, task=\"multiclass\", num_classes=NUM_CLASSES, average=None)\n",
    "\n",
    "                    for cls in range(NUM_CLASSES):\n",
    "                        city_class_metrics[city][cls]['precision'] += precision_per_class[cls].item()\n",
    "                        city_class_metrics[city][cls]['recall'] += recall_per_class[cls].item()\n",
    "                        city_class_metrics[city][cls]['f1'] += f1_per_class[cls].item()\n",
    "                        city_class_metrics[city][cls]['iou'] += iou_per_class[cls].item()\n",
    "                        city_class_metrics[city][cls]['count'] += 1\n",
    "\n",
    "    # Build the DataFrame for reporting\n",
    "    all_records = []\n",
    "    for city, class_metrics in city_class_metrics.items():\n",
    "        for cls_idx, metrics in class_metrics.items():\n",
    "            count = metrics['count']\n",
    "            all_records.append({\n",
    "                \"City\": city_translation.get(city, city.capitalize()),\n",
    "                \"Class\": class_names[cls_idx],\n",
    "                \"Precision\": metrics['precision'] / count if count else 0,\n",
    "                \"Recall\": metrics['recall'] / count if count else 0,\n",
    "                \"F1\": metrics['f1'] / count if count else 0,\n",
    "                \"IoU\": metrics['iou'] / count if count else 0\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "\n",
    "# List of (model results directory, test dataset directory) pairs to evaluate\n",
    "model_dataset_pairs = [\n",
    "    (\"YOUR_RESULTS_DIR_65_35\", \"YOUR_DATASET_DIR_65_35/test\"),\n",
    "    (\"YOUR_RESULTS_DIR_70_30\", \"YOUR_DATASET_DIR_70_30/test\"),\n",
    "    (\"YOUR_RESULTS_DIR_75_25\", \"YOUR_DATASET_DIR_75_25/test\"),\n",
    "    (\"YOUR_RESULTS_DIR_95_5\", \"YOUR_DATASET_DIR_95_5/test\")\n",
    "]\n",
    "\n",
    "for model_dir, dataset_dir in model_dataset_pairs:\n",
    "    df = evaluate_and_collect(model_dir, dataset_dir)\n",
    "    split_name = model_dir.split('_')[-2] + \"-\" + model_dir.split('_')[-1]  # Adjust to match your naming pattern\n",
    "    df.to_csv(f\"deeplabv3_metrics_{split_name}.csv\", index=False)\n",
    "    print(f\"✅ Saved: deeplabv3_metrics_{split_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e068602-ece1-4539-a02c-f74880a5cfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
