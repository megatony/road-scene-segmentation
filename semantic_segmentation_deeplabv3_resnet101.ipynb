{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb204150-2d31-42ea-a0ab-32f32ba304fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda, GPU count: 2\n",
      "2 GPU ile model paralelleştiriliyor...\n",
      "Checkpoint bulunamadı. Eğitim 0'dan başlıyor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  91%|█████████▏| 1219/1333 [34:49<03:17,  1.74s/it] "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "README: DeepLabV3+ResNet101 Semantic Segmentation Pipeline (PyTorch, Albumentations)\n",
    "\n",
    "This script trains a DeepLabV3+ResNet101 model for semantic segmentation on a custom dataset.\n",
    "It uses PyTorch, Albumentations for augmentation, and supports multi-GPU training.\n",
    "\n",
    "Pipeline:\n",
    "1. Custom Dataset class loads images and corresponding masks from a given directory.\n",
    "2. Data augmentations (resize, flip, normalization) are applied with Albumentations.\n",
    "3. DataLoaders are created for training, validation, and testing.\n",
    "4. Model is initialized (DeepLabV3+ResNet101) with a custom number of classes.\n",
    "5. Weighted CrossEntropyLoss is used for imbalanced datasets.\n",
    "6. Training supports checkpointing and multi-GPU (DataParallel).\n",
    "7. The best model is saved at the end of training.\n",
    "\n",
    "How to use:\n",
    "- Place your images as JPGs and masks as PNGs in the appropriate 'train', 'valid', and 'test' folders:\n",
    "    YOUR_DATASET_DIR/\n",
    "        train/\n",
    "            image1.jpg\n",
    "            image1_mask.png\n",
    "            ...\n",
    "        valid/\n",
    "        test/\n",
    "- Set the number of classes and class weights as needed.\n",
    "- Adjust batch size and number of workers based on your GPU memory.\n",
    "\n",
    "Author: Bahadir Akin Akgul\n",
    "Date: 13.07.2025\n",
    "\n",
    "Requirements:\n",
    "- torch\n",
    "- torchvision\n",
    "- albumentations\n",
    "- opencv-python\n",
    "- numpy\n",
    "- tqdm\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}, GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Data paths (CHANGE these to your own directory)\n",
    "DATA_DIR = \"YOUR_DATASET_DIR\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VALID_DIR = os.path.join(DATA_DIR, \"valid\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "# Albumentations transforms\n",
    "transform = A.Compose([\n",
    "    A.Resize(1024, 768),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "# Custom Dataset class for segmentation\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        mask_path = img_path.replace(\".jpg\", \"_mask.png\")\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if mask is None or image.shape[:2] != mask.shape:\n",
    "            print(f\"Warning: {mask_path} could not be loaded! Image shape: {image.shape}, Mask shape: {mask.shape if mask is not None else 'None'}\")\n",
    "            mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        else:\n",
    "            mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        mask = mask.astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"].long()\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# DataLoaders (drop_last=True is important for batch consistency)\n",
    "BATCH_SIZE = 4  # Adjust according to your GPU memory\n",
    "train_dataset = SegmentationDataset(TRAIN_DIR, transform=transform)\n",
    "valid_dataset = SegmentationDataset(VALID_DIR, transform=transform)\n",
    "test_dataset = SegmentationDataset(TEST_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "# Clean up memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Model setup\n",
    "NUM_CLASSES = 4\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet101(weights=\"DEFAULT\")\n",
    "model.classifier[4] = torch.nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "if hasattr(model, \"aux_classifier\") and model.aux_classifier is not None:\n",
    "    model.aux_classifier[4] = torch.nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Multi-GPU support\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Parallelizing model on {torch.cuda.device_count()} GPUs...\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Loss function and optimizer (adjust weights for your own dataset)\n",
    "class_weights = torch.tensor([1.0, 2.0, 2.0, 4.0]).to(DEVICE)  # Tune according to class distribution\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# --- CHECKPOINT FUNCTIONS ---\n",
    "checkpoint_path = \"checkpoint_resnet101.pth\"\n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "        is_dataparallel = isinstance(model, torch.nn.DataParallel)\n",
    "        model_to_load = model.module if is_dataparallel else model\n",
    "        model_to_load.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"]\n",
    "        print(f\"Checkpoint loaded. Continuing training from epoch {start_epoch}.\")\n",
    "        return model, optimizer, start_epoch\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "        return model, optimizer, 0\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, optimizer, criterion, start_epoch=0, epochs=100, checkpoint_path=checkpoint_path):\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)[\"out\"]\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "# Training and checkpoint loading\n",
    "model, optimizer, start_epoch = load_checkpoint(model, optimizer, checkpoint_path=checkpoint_path)\n",
    "\n",
    "train_model(\n",
    "    model, train_loader, valid_loader, optimizer, criterion,\n",
    "    start_epoch=start_epoch, epochs=100, checkpoint_path=checkpoint_path\n",
    ")\n",
    "\n",
    "# Save the final trained model\n",
    "model_to_save = model.module if isinstance(model, torch.nn.DataParallel) else model\n",
    "torch.save(model_to_save.state_dict(), \"trained_model_resnet101.pth\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76eaf5-e0ab-4ad3-9e01-05f3199aa48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
