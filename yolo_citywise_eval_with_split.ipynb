{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cef32af-0b39-47d2-a785-ac26e0496734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔵 ISTANBUL (70-30) test ediliyor...\n",
      "Ultralytics 8.3.91 🚀 Python-3.10.15 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "                                                       CUDA:1 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "Model summary (fused): 112 layers, 43,608,921 parameters, 0 gradients, 164.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /truba/home/baakgul/roadtr-14032025-istanbul/test/labels.cache... 751 images, 0 backgrounds, 0 corrupt: 100%|██████████| 751/751 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1590, len(boxes) = 18766. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:27<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        751      18766      0.827      0.653        0.7      0.505\n",
      "            pedestrian        560       8383       0.74      0.349      0.417      0.209\n",
      "                  road        750        804      0.935       0.93      0.948      0.815\n",
      "               vehicle        739       9579      0.806       0.68      0.735       0.49\n",
      "Speed: 0.8ms preprocess, 25.8ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/yolo-8-75-252-70-30-istanbul\u001b[0m\n",
      "📄 ISTANBUL için class sonuçları: /arf/home/baakgul/runs/detect/yolo-8-75-252/city_results_70-30/istanbul/istanbul_class_results.csv\n",
      "✅ ISTANBUL (70-30) test tamamlandı!\n",
      "\n",
      "🔵 PARIS (70-30) test ediliyor...\n",
      "Ultralytics 8.3.91 🚀 Python-3.10.15 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "                                                       CUDA:1 (Tesla P100-PCIE-16GB, 16269MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /truba/home/baakgul/roadtr-14032025-paris/test/labels.cache... 48 images, 0 backgrounds, 0 corrupt: 100%|██████████| 48/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 239, len(boxes) = 1374. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         48       1374      0.744      0.663      0.689      0.485\n",
      "            pedestrian         42        598      0.578      0.363      0.384      0.188\n",
      "                  road         48         58       0.88      0.882      0.912      0.781\n",
      "               vehicle         48        718      0.774      0.744      0.771      0.488\n",
      "Speed: 0.2ms preprocess, 24.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/yolo-8-75-252-70-30-paris\u001b[0m\n",
      "📄 PARIS için class sonuçları: /arf/home/baakgul/runs/detect/yolo-8-75-252/city_results_70-30/paris/paris_class_results.csv\n",
      "✅ PARIS (70-30) test tamamlandı!\n",
      "\n",
      "🔵 MUNIH (70-30) test ediliyor...\n",
      "Ultralytics 8.3.91 🚀 Python-3.10.15 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "                                                       CUDA:1 (Tesla P100-PCIE-16GB, 16269MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /truba/home/baakgul/roadtr-14032025-munih/test/labels.cache... 245 images, 1 backgrounds, 0 corrupt: 100%|██████████| 245/245 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 189, len(boxes) = 2656. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:10<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        245       2656      0.794      0.796      0.817      0.561\n",
      "            pedestrian         97        431      0.661      0.639      0.638       0.32\n",
      "                  road        244        269      0.944      0.943      0.976       0.82\n",
      "               vehicle        236       1956      0.777      0.807      0.836      0.541\n",
      "Speed: 2.1ms preprocess, 26.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/yolo-8-75-252-70-30-munih\u001b[0m\n",
      "📄 MUNIH için class sonuçları: /arf/home/baakgul/runs/detect/yolo-8-75-252/city_results_70-30/munih/munih_class_results.csv\n",
      "✅ MUNIH (70-30) test tamamlandı!\n",
      "\n",
      "🔵 MARSILYA (70-30) test ediliyor...\n",
      "Ultralytics 8.3.91 🚀 Python-3.10.15 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "                                                       CUDA:1 (Tesla P100-PCIE-16GB, 16269MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /truba/home/baakgul/roadtr-14032025-marsilya/test/labels.cache... 273 images, 0 backgrounds, 0 corrupt: 100%|██████████| 273/273 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:11<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        273       4969      0.819      0.695      0.728      0.509\n",
      "            pedestrian        144       1247      0.675      0.331      0.385      0.169\n",
      "                  road        265        269      0.971      0.989      0.981      0.859\n",
      "               vehicle        272       3453      0.812      0.764      0.817        0.5\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/yolo-8-75-252-70-30-marsilya\u001b[0m\n",
      "📄 MARSILYA için class sonuçları: /arf/home/baakgul/runs/detect/yolo-8-75-252/city_results_70-30/marsilya/marsilya_class_results.csv\n",
      "✅ MARSILYA (70-30) test tamamlandı!\n",
      "\n",
      "📊 Toplam ortalama eklendi.\n",
      "🏁 70-30 split için tüm şehir class sonuçları '/arf/home/baakgul/runs/detect/yolo-8-75-252/city_results_70-30/city_class_results_70-30.csv' dosyasına kaydedildi!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "README: YOLO City-wise and Class-wise Model Evaluation for Custom Split\n",
    "\n",
    "This script:\n",
    "- Evaluates a YOLO model on the test split for multiple cities (using city-specific data.yaml files),\n",
    "- Collects and saves per-class metrics (Precision, Recall, mAP50, mAP50-95) for each city,\n",
    "- Exports a summary CSV per city, and an aggregated CSV for all cities, including a row with the overall mean.\n",
    "\n",
    "How to use:\n",
    "- Set 'model_name', 'weights_path', and the dataset base path as needed.\n",
    "- Define your city list and folder conventions.\n",
    "- Run the script or call the function for the desired split/model.\n",
    "- CSV outputs will be available under [city_results_{split_ratio}].\n",
    "\n",
    "Requirements:\n",
    "- ultralytics\n",
    "- torch\n",
    "- pandas\n",
    "\n",
    "Author: Bahadir Akin Akgul\n",
    "Date: 13.07.2025\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model_on_split(split_ratio: str, model_name: str):\n",
    "    # === Paths ===\n",
    "    weights_path = f'/PATH/TO/runs/detect/{model_name}/weights/best.pt'\n",
    "    results_base = f'/PATH/TO/runs/detect/{model_name}/city_results_{split_ratio}'\n",
    "\n",
    "    # === List of cities ===\n",
    "    cities = ['istanbul', 'paris', 'munich', 'marseille']\n",
    "\n",
    "    # === Dataset root\n",
    "    city_dataset_base = Path('/PATH/TO/dataset-root')\n",
    "\n",
    "    # === Create results folder\n",
    "    city_results_base = Path(results_base)\n",
    "    city_results_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # === Load model\n",
    "    model = YOLO(weights_path)\n",
    "\n",
    "    # === Collect all results\n",
    "    all_results = []\n",
    "\n",
    "    for city in cities:\n",
    "        print(f\"\\nTesting {city.upper()} ({split_ratio})...\")\n",
    "\n",
    "        # Dataset/data.yaml path for the city\n",
    "        city_dataset = city_dataset_base / f'roadtr-YYYYMMDD-{city}'\n",
    "        city_data_yaml = city_dataset / 'data.yaml'\n",
    "\n",
    "        # Output directory for this city\n",
    "        city_save_dir = city_results_base / city\n",
    "        city_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # model.val() — use test split\n",
    "        results = model.val(\n",
    "            data=str(city_data_yaml),\n",
    "            split='test',\n",
    "            imgsz=1024,\n",
    "            batch=64,\n",
    "            device=[0, 1],        # Adjust as needed\n",
    "            save_dir=str(city_save_dir),\n",
    "            save_json=False,\n",
    "            verbose=True,\n",
    "            plots=True,\n",
    "            conf=0.001,\n",
    "            rect=True,\n",
    "            name=f'{model_name}-{split_ratio}-{city}'\n",
    "        )\n",
    "\n",
    "        # Collect per-class metrics\n",
    "        names = results.names\n",
    "        p = results.box.p\n",
    "        r = results.box.r\n",
    "        ap50 = results.box.all_ap[:, 0]\n",
    "        ap = results.box.ap\n",
    "        n_classes = len(names)\n",
    "\n",
    "        city_result_rows = []\n",
    "        for class_id in range(n_classes):\n",
    "            result = {\n",
    "                'Model': model_name,\n",
    "                'Split': split_ratio,\n",
    "                'City': city,\n",
    "                'Class': names[class_id],\n",
    "                'Precision': round(float(p[class_id]), 3),\n",
    "                'Recall': round(float(r[class_id]), 3),\n",
    "                'mAP50': round(float(ap50[class_id]), 3),\n",
    "                'mAP50-95': round(float(ap[class_id]), 3),\n",
    "            }\n",
    "            all_results.append(result)\n",
    "            city_result_rows.append(result)\n",
    "\n",
    "        # City-specific class results CSV\n",
    "        city_df = pd.DataFrame(city_result_rows)\n",
    "        city_csv_path = city_save_dir / f'{city}_class_results.csv'\n",
    "        city_df.to_csv(city_csv_path, index=False)\n",
    "        print(f\"Class results for {city.upper()} saved to: {city_csv_path}\")\n",
    "\n",
    "        print(f\"Finished testing {city.upper()} ({split_ratio})\")\n",
    "\n",
    "    # Combine all cities results\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    # Add overall mean row\n",
    "    mean_row = {\n",
    "        'Model': model_name,\n",
    "        'Split': split_ratio,\n",
    "        'City': 'ALL',\n",
    "        'Class': 'ALL_MEAN',\n",
    "        'Precision': round(df['Precision'].mean(), 3),\n",
    "        'Recall': round(df['Recall'].mean(), 3),\n",
    "        'mAP50': round(df['mAP50'].mean(), 3),\n",
    "        'mAP50-95': round(df['mAP50-95'].mean(), 3)\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "\n",
    "    # Save all results\n",
    "    csv_path = city_results_base / f'city_class_results_{split_ratio}.csv'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"\\nOverall mean row added.\")\n",
    "    print(f\"All city/class results for split {split_ratio} saved to '{csv_path}'\")\n",
    "\n",
    "\n",
    "# === Usage Example ===\n",
    "# Uncomment and edit as needed to run for your experiments:\n",
    "\n",
    "# evaluate_model_on_split('65-35', 'yolo-10-65-35-batch-17')\n",
    "# evaluate_model_on_split('65-35', 'exp_6535')\n",
    "# evaluate_model_on_split('95-5', 'yolo-10-95-52')\n",
    "# evaluate_model_on_split('95-5', 'exp_955')\n",
    "# evaluate_model_on_split('75-25', 'yolo-10-75-25-2')\n",
    "# evaluate_model_on_split('75-25', 'yolo-8-75-252')\n",
    "# evaluate_model_on_split('70-30', 'yolov10-70-30')\n",
    "# evaluate_model_on_split('70-30', 'yolo-8-75-252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c79f0-d9c6-4274-a243-6ec561e3f8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
