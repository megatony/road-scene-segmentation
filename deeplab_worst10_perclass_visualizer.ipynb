{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d494d8-9d14-497e-bbaf-ddf6da959fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Inferencing:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1316/1316 [06:20<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kötü sonuçlar başarıyla kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "README: DeepLabV3 Worst-10 IoU Visualizer by Class and City\n",
    "\n",
    "This script:\n",
    "- Loads a trained DeepLabV3+MobileNetV3 segmentation model,\n",
    "- Runs inference on a test image set,\n",
    "- Calculates per-class IoU between ground truth and predictions for each city,\n",
    "- Saves the **worst 10** (lowest IoU) results for each class and city as visualizations:\n",
    "    - original.jpg (original image)\n",
    "    - label.jpg    (ground truth mask overlay, always green)\n",
    "    - prediction.jpg (predicted mask overlay, class color)\n",
    "\n",
    "How to use:\n",
    "- Set MODEL_PATH, IMAGE_DIR, and OUTPUT_DIR as needed.\n",
    "- Edit city and class definitions as appropriate.\n",
    "- Run the script; images will be saved under OUTPUT_DIR/[class]/[city].\n",
    "\n",
    "Requirements:\n",
    "- Python 3.8+\n",
    "- torch, torchvision\n",
    "- opencv-python\n",
    "- numpy\n",
    "- tqdm\n",
    "\n",
    "Author: Bahadir Akin Akgul\n",
    "Date: 13.07.2025\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large\n",
    "\n",
    "# === SETTINGS ===\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"PATH_TO_TRAINED_MODEL/trained_model.pth\"\n",
    "IMAGE_DIR = Path(\"PATH_TO_TEST_IMAGES\")\n",
    "OUTPUT_DIR = Path(\"deeplabv3-worst-10-by-class-city\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class_names = ['Background', 'Person', 'Road', 'Vehicle']\n",
    "class_ids = [1, 2, 3]  # Only evaluated classes\n",
    "\n",
    "city_keywords = {\n",
    "    'istanbul': ['libadiye', 'levent', 'taksim', 'ciragan', 'barbaros', 'dolmabahce', 'bagdat', 'muallim', 'katar'],\n",
    "    'paris': ['paris-champs'],\n",
    "    'munich': ['munih'],\n",
    "    'marseille': ['marsilya']\n",
    "}\n",
    "city_translation = {\n",
    "    'istanbul': 'Istanbul',\n",
    "    'paris': 'Paris',\n",
    "    'munich': 'Munich',\n",
    "    'marseille': 'Marseille',\n",
    "    'unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = deeplabv3_mobilenet_v3_large(weights=None, num_classes=4)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "# === TRANSFORM ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "def compute_iou(gt, pred, cls):\n",
    "    gt_mask = (gt == cls)\n",
    "    pred_mask = (pred == cls)\n",
    "    intersection = np.logical_and(gt_mask, pred_mask).sum()\n",
    "    union = np.logical_or(gt_mask, pred_mask).sum()\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "def get_city_from_name(name):\n",
    "    for city, keywords in city_keywords.items():\n",
    "        if any(k in name for k in keywords):\n",
    "            return city\n",
    "    return 'unknown'\n",
    "\n",
    "results_by_class_city = {cls: {city: [] for city in city_translation} for cls in class_ids}\n",
    "image_files = list(IMAGE_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(\"Inferencing:\")\n",
    "for image_file in tqdm(image_files):\n",
    "    name = image_file.stem\n",
    "    city = get_city_from_name(name)\n",
    "    mask_file = IMAGE_DIR / f\"{name}_mask.png\"\n",
    "\n",
    "    if not mask_file.exists():\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(str(image_file))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(str(mask_file), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    inp = transform(img_rgb).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = model(inp)[\"out\"]\n",
    "    output = torch.argmax(output.squeeze(), dim=0).cpu().numpy()\n",
    "\n",
    "    for cls_id in class_ids:\n",
    "        if np.sum(mask == cls_id) == 0:\n",
    "            continue\n",
    "        iou = compute_iou(mask, output, cls_id)\n",
    "        if iou > 0:\n",
    "            results_by_class_city[cls_id][city].append({\n",
    "                \"filename\": name,\n",
    "                \"iou\": iou,\n",
    "                \"image\": img.copy(),\n",
    "                \"gt_mask\": mask.copy(),\n",
    "                \"pred_mask\": output.copy()\n",
    "            })\n",
    "\n",
    "# === SAVE WORST 10 VISUALIZATIONS ===\n",
    "colors = {\n",
    "    1: (0, 255, 255),  # pedestrian (yellow)\n",
    "    2: (255, 0, 255),  # road (magenta)\n",
    "    3: (0, 0, 255),    # vehicle (red)\n",
    "}\n",
    "\n",
    "def overlay_mask(img, mask, cls, color):\n",
    "    overlay = img.copy()\n",
    "    colored = np.zeros_like(img, dtype=np.uint8)\n",
    "    colored[:, :] = color\n",
    "    mask_binary = (mask == cls).astype(np.uint8)\n",
    "    mask_exp = np.stack([mask_binary]*3, axis=-1)\n",
    "    overlay = np.where(mask_exp == 1, cv2.addWeighted(colored, 0.4, overlay, 0.6, 0), overlay)\n",
    "    return overlay\n",
    "\n",
    "for cls_id, city_results in results_by_class_city.items():\n",
    "    cls_name = {1: \"pedestrian\", 2: \"road\", 3: \"vehicle\"}[cls_id]\n",
    "\n",
    "    for city, results in city_results.items():\n",
    "        if not results:\n",
    "            continue\n",
    "\n",
    "        worst10 = sorted(results, key=lambda x: x[\"iou\"])[:10]\n",
    "        out_dir = OUTPUT_DIR / cls_name / city_translation[city]\n",
    "        for i, item in enumerate(worst10, 1):\n",
    "            base = out_dir / f\"{i:02d}_{item['filename']}\"\n",
    "            base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            image = item[\"image\"]\n",
    "            gt = item[\"gt_mask\"]\n",
    "            pred = item[\"pred_mask\"]\n",
    "            color = colors[cls_id]\n",
    "\n",
    "            cv2.imwrite(str(base / \"original.jpg\"), image)\n",
    "            cv2.imwrite(str(base / \"label.jpg\"), overlay_mask(image, gt, cls_id, (0, 255, 0)))  # green for GT\n",
    "            cv2.imwrite(str(base / \"prediction.jpg\"), overlay_mask(image, pred, cls_id, color))\n",
    "\n",
    "print(\"Worst-case visualizations saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610d7bde-c93a-4b0e-a729-eb0a5679162e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Inferencing:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1316/1316 [14:23<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kötü sonuçlar başarıyla kaydedildi (300 DPI).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large\n",
    "from PIL import Image\n",
    "\n",
    "# === AYARLAR ===\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"road-tr-od-ss-70-30-results/trained_model.pth\"\n",
    "IMAGE_DIR = Path(\"yolo-seg-11042025/road-tr-od-ss/test\")\n",
    "OUTPUT_DIR = Path(\"deeplabv3-worst-10-by-class-city-300dpi\")  # GÜNCELLENDİ\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class_names = ['Background', 'Person', 'Road', 'Vehicle']\n",
    "class_ids = [1, 2, 3]  # Sadece analiz edilen sınıflar\n",
    "\n",
    "city_keywords = {\n",
    "    'istanbul': ['libadiye', 'levent', 'taksim', 'ciragan', 'barbaros', 'dolmabahce', 'bagdat', 'muallim', 'katar'],\n",
    "    'paris': ['paris-champs'],\n",
    "    'munih': ['munih'],\n",
    "    'marsilya': ['marsilya']\n",
    "}\n",
    "city_translation = {\n",
    "    'istanbul': 'Istanbul',\n",
    "    'paris': 'Paris',\n",
    "    'munih': 'Munich',\n",
    "    'marsilya': 'Marseille',\n",
    "    'unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "# === MODEL YÜKLE ===\n",
    "model = deeplabv3_mobilenet_v3_large(weights=None, num_classes=4)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "# === HAZIRLIK ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "def compute_iou(gt, pred, cls):\n",
    "    gt_mask = (gt == cls)\n",
    "    pred_mask = (pred == cls)\n",
    "    intersection = np.logical_and(gt_mask, pred_mask).sum()\n",
    "    union = np.logical_or(gt_mask, pred_mask).sum()\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "def get_city_from_name(name):\n",
    "    for city, keywords in city_keywords.items():\n",
    "        if any(k in name for k in keywords):\n",
    "            return city\n",
    "    return 'unknown'\n",
    "\n",
    "def overlay_mask(img, mask, cls, color):\n",
    "    overlay = img.copy()\n",
    "    colored = np.zeros_like(img, dtype=np.uint8)\n",
    "    colored[:, :] = color\n",
    "    mask_binary = (mask == cls).astype(np.uint8)\n",
    "    mask_exp = np.stack([mask_binary]*3, axis=-1)\n",
    "    overlay = np.where(mask_exp == 1, cv2.addWeighted(colored, 0.4, overlay, 0.6, 0), overlay)\n",
    "    return overlay\n",
    "\n",
    "def save_with_dpi(img_array, path, dpi=(300, 300)):\n",
    "    img_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img_rgb)\n",
    "    img_pil.save(path, dpi=dpi, quality=95)\n",
    "\n",
    "results_by_class_city = {cls: {city: [] for city in city_translation} for cls in class_ids}\n",
    "image_files = list(IMAGE_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(\"Inferencing:\")\n",
    "for image_file in tqdm(image_files):\n",
    "    name = image_file.stem\n",
    "    city = get_city_from_name(name)\n",
    "    mask_file = IMAGE_DIR / f\"{name}_mask.png\"\n",
    "\n",
    "    if not mask_file.exists():\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(str(image_file))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(str(mask_file), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    inp = transform(img_rgb).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = model(inp)[\"out\"]\n",
    "    output = torch.argmax(output.squeeze(), dim=0).cpu().numpy()\n",
    "\n",
    "    for cls_id in class_ids:\n",
    "        if np.sum(mask == cls_id) == 0:\n",
    "            continue\n",
    "        iou = compute_iou(mask, output, cls_id)\n",
    "        if iou > 0:\n",
    "            results_by_class_city[cls_id][city].append({\n",
    "                \"filename\": name,\n",
    "                \"iou\": iou,\n",
    "                \"image\": img.copy(),\n",
    "                \"gt_mask\": mask.copy(),\n",
    "                \"pred_mask\": output.copy()\n",
    "            })\n",
    "\n",
    "# === EN KÖTÜ 10 GÖRSELİ KAYDET ===\n",
    "colors = {\n",
    "    1: (0, 255, 255),  # pedestrian\n",
    "    2: (255, 0, 255),  # road\n",
    "    3: (0, 0, 255),    # vehicle\n",
    "}\n",
    "\n",
    "for cls_id, city_results in results_by_class_city.items():\n",
    "    cls_name = {1: \"pedestrian\", 2: \"road\", 3: \"vehicle\"}[cls_id]\n",
    "\n",
    "    for city, results in city_results.items():\n",
    "        if not results:\n",
    "            continue\n",
    "\n",
    "        top10 = sorted(results, key=lambda x: x[\"iou\"])[:10]\n",
    "        out_dir = OUTPUT_DIR / cls_name / city_translation[city]\n",
    "        for i, item in enumerate(top10, 1):\n",
    "            base = out_dir / f\"{i:02d}_{item['filename']}\"\n",
    "            base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            image = item[\"image\"]\n",
    "            gt = item[\"gt_mask\"]\n",
    "            pred = item[\"pred_mask\"]\n",
    "            color = colors[cls_id]\n",
    "\n",
    "            save_with_dpi(image, str(base / \"original.jpg\"))\n",
    "            save_with_dpi(overlay_mask(image, gt, cls_id, (0, 255, 0)), str(base / \"label.jpg\"))  # ground truth - green\n",
    "            save_with_dpi(overlay_mask(image, pred, cls_id, color), str(base / \"prediction.jpg\"))\n",
    "\n",
    "print(\"✅ Kötü sonuçlar başarıyla kaydedildi (300 DPI).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c95bdf-4dd5-470d-990a-943e7658e0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
